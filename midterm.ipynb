{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Dealing with the Data\n",
    "You identify the following important documents that, if used for context, you believe will help people understand what’s happening now:\n",
    "Your boss, the SVP of Technology, green-lighted this project to drive the adoption of AI throughout the enterprise.  It will be a nice showpiece for the upcoming conference and the big AI initiative announcement the CEO is planning.\n",
    "\n",
    "https://www.whitehouse.gov/wp-content/uploads/2022/10/Blueprint-for-an-AI-Bill-of-Rights.pdf\n",
    "\n",
    "https://www.whitehouse.gov/wp-content/uploads/2022/10/Blueprint-for-an-AI-Bill-of-Rights.pdf\n",
    "\n",
    "\n",
    "Your boss, the SVP of Technology, green-lighted this project to drive the adoption of AI throughout the enterprise.  It will be a nice showpiece for the upcoming conference and the big AI initiative announcement the CEO is planning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU langgraph langchain langchain_openai langchain_experimental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU --disable-pip-version-check qdrant-client pymupdf tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAGAS DEPENDENCIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "/bin/bash: 0.4.0: No such file or directory\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "/bin/bash: 0.4.0: No such file or directory\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU langsmith langchain-qdrant ragas\n",
    "%pip install langchain-community>=0.3.0,<0.4.0\n",
    "%pip install langchain-core>=0.3.0,<0.4.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 137 documents\n",
      "Loaded [Document(metadata={'source': 'https://www.whitehouse.gov/wp-content/uploads/2022/10/Blueprint-for-an-AI-Bill-of-Rights.pdf', 'file_path': 'https://www.whitehouse.gov/wp-content/uploads/2022/10/Blueprint-for-an-AI-Bill-of-Rights.pdf', 'page': 0, 'total_pages': 73, 'format': 'PDF 1.6', 'title': 'Blueprint for an AI Bill of Rights', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Adobe Illustrator 26.3 (Macintosh)', 'producer': 'iLovePDF', 'creationDate': \"D:20220920133035-04'00'\", 'modDate': \"D:20221003104118-04'00'\", 'trapped': ''}, page_content=' \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nBLUEPRINT FOR AN \\nAI BILL OF \\nRIGHTS \\nMAKING AUTOMATED \\nSYSTEMS WORK FOR \\nTHE AMERICAN PEOPLE \\nOCTOBER 2022 \\n')] documents\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "\n",
    "docB = PyMuPDFLoader(\"https://www.whitehouse.gov/wp-content/uploads/2022/10/Blueprint-for-an-AI-Bill-of-Rights.pdf\").load()\n",
    "docN = PyMuPDFLoader(\"https://nvlpubs.nist.gov/nistpubs/ai/NIST.AI.600-1.pdf\").load()\n",
    "\n",
    "documents = docB + docN\n",
    "print(f\"Loaded {len(documents)} documents\")\n",
    "print(f\"Loaded {documents[:1]} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 363 chunks\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "def tiktoken_len(text):\n",
    "    tokens = tiktoken.encoding_for_model(\"gpt-4o-mini\").encode(\n",
    "        text,\n",
    "    )\n",
    "    return len(tokens)\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 300,\n",
    "    chunk_overlap = 0,\n",
    "    length_function = tiktoken_len,\n",
    ")\n",
    "\n",
    "split_chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "print(f\"Split {len(split_chunks)} chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Qdrant\n",
    "\n",
    "qdrant_vectorstore = Qdrant.from_documents(\n",
    "    split_chunks,\n",
    "    embedding_model,\n",
    "    location=\":memory:\",\n",
    "    collection_name=\"extending_context_window_llama_3\",\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "qdrant_retriever = qdrant_vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "RAG_PROMPT = \"\"\"\n",
    "CONTEXT:\n",
    "{context}\n",
    "\n",
    "QUERY:\n",
    "{question}\n",
    "\n",
    "You are a helpful assistant. Use the available context to answer the question only. If the question is not in the context then, say 'I don't know brah!'.\n",
    "\"\"\"\n",
    "\n",
    "rag_prompt = ChatPromptTemplate.from_template(RAG_PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "openai_chat_model = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "#Context is both the question and the output of the qdrant retriever \n",
    "#The question is passed through the qdrant retriever to get the context\n",
    "#Question is passed through the RAG prompt and then the openai chat model\n",
    "rag_chain = (\n",
    "    {\"context\": itemgetter(\"question\") | qdrant_retriever, \"question\": itemgetter(\"question\")}\n",
    "    | rag_prompt | openai_chat_model | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CBRN Information or Capabilities refer to information and capabilities related to Chemical, Biological, Radiological, and Nuclear threats. The context highlights the need to periodically evaluate whether models may misuse CBRN information or capabilities, as well as the importance of governance and oversight concerning dangerous, violent, or hateful content associated with these capabilities. Additionally, it emphasizes establishing policies and procedures for risk measurement related to CBRN information within structured frameworks.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke({\"question\" : \"tell about CBRN Information or Capabilities?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TASK 3: RAGAS FRAMEWORK - GENERATION SYNTHETIC DATA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset.generator import TestsetGenerator\n",
    "from ragas.testset.evolutions import simple, reasoning, multi_context\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "generator_llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "critic_llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "generator = TestsetGenerator.from_langchain(\n",
    "    generator_llm,\n",
    "    critic_llm,\n",
    "    embeddings\n",
    ")\n",
    "\n",
    "distributions = {\n",
    "    simple: 0.5,\n",
    "    multi_context: 0.4,\n",
    "    reasoning: 0.1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffb6054d7b224a42bddd1b89a7148a31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes:   0%|          | 0/284 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filename and doc_id are the same for all nodes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c48c1870848458c9aeec2f7be3f3111",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 3, 'structure': 2, 'relevance': 3, 'score': 2.5}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['Human subjects', 'Content provenance data', 'Data privacy', 'AI system performance', 'Pre-deployment testing']\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 1, 'depth': 1, 'structure': 2, 'relevance': 2, 'score': 1.5}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['Technical companion', 'AI Bill of Rights', 'Algorithmic discrimination protections', 'Data privacy', 'Human alternatives']\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 3, 'structure': 2, 'relevance': 3, 'score': 2.5}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['Information sharing', 'Feedback mechanisms', 'Negative impact', 'GAI systems', 'AI risks']\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 1, 'depth': 1, 'structure': 2, 'relevance': 2, 'score': 1.5}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['Technical companion', 'AI Bill of Rights', 'Algorithmic discrimination protections', 'Data privacy', 'Human alternatives']\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"How can data privacy be ensured when conducting evaluations involving human subjects in GAI applications?\"\n",
      "[ragas.testset.evolutions.INFO] seed question generated: What is the importance of considering human alternatives, consideration, and fallback in the context of the AI Bill of Rights?\n",
      "[ragas.testset.evolutions.INFO] seed question generated: How can organizations verify information sharing and feedback mechanisms regarding any negative impact from GAI systems?\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"How is data privacy addressed in the technical companion to the Blueprint for an AI Bill of Rights?\"\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 3, 'structure': 2, 'relevance': 3, 'score': 2.5}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['GAI system incidents', 'Organizational risk management authority', 'Remediation plan', 'Deactivation criteria', 'Third-party GAI resources']\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks how organizations can verify information sharing and feedback mechanisms related to negative impacts from GAI (Generative AI) systems. It is specific in its focus on organizations and the verification of mechanisms, which makes the intent clear. However, the question could benefit from additional context regarding what types of negative impacts are being referred to (e.g., ethical concerns, misinformation, operational issues) and what specific aspects of information sharing and feedback mechanisms are of interest (e.g., processes, tools, metrics). Providing this context would enhance clarity and answerability.', 'verdict': 1}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question is clear and specific, asking about methods to ensure data privacy during evaluations involving human subjects in Generative AI (GAI) applications. It does not rely on external references and can be understood independently. The intent is clear, seeking information on data privacy practices in a specific context. Therefore, it meets the criteria for clarity and answerability.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] simple question generated: \"How can data privacy be ensured when conducting evaluations involving human subjects in GAI applications?\"\n",
      "[ragas.testset.evolutions.INFO] seed question generated: What procedures should be established and maintained for escalating GAI system incidents to the organizational risk management authority when specific criteria for deactivation or disengagement is met?\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks about how data privacy is addressed in the technical companion to the Blueprint for an AI Bill of Rights. It is specific in its focus on data privacy and the particular document (the technical companion) related to the AI Bill of Rights. However, the question assumes familiarity with the content of this technical companion without providing any context or details about it. To improve clarity and answerability, the question could include a brief description of what the technical companion entails or specify the aspects of data privacy being inquired about (e.g., principles, guidelines, specific measures).', 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] rewritten question: \"How is data privacy addressed in the technical companion to the Blueprint for an AI Bill of Rights?\"\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] multicontext question generated: \"How can data privacy be maintained in GAI evaluations involving human subjects to ensure compliance with applicable requirements and protect the privacy of individuals?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the importance of considering human alternatives, consideration, and fallback in relation to the AI Bill of Rights. While it specifies a clear topic (AI Bill of Rights) and the aspects of interest (human alternatives, consideration, and fallback), it may be somewhat vague regarding what is meant by 'consideration' and 'fallback'. Additionally, the phrase 'in the context of' could be interpreted in various ways, leading to ambiguity. To improve clarity and answerability, the question could define what is meant by 'consideration' and 'fallback', and specify how these concepts relate to the AI Bill of Rights. For example, it could ask how these elements contribute to ethical AI practices or the protection of human rights.\", 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] rewritten question: What is the importance of considering human alternatives, consideration, and fallback in the context of the AI Bill of Rights?\n",
      "[ragas.testset.evolutions.DEBUG] answer generated: {'answer': 'Organizations can verify information sharing and feedback mechanisms regarding any negative impact from GAI systems by implementing policies and practices that collect, consider, prioritize, and integrate feedback from external sources related to potential individual and societal impacts of AI risks. They can also allocate time and resources for outreach, feedback, and recourse processes in GAI system development, document interactions with GAI systems to users prior to interactive activities, and categorize different types of GAI content with associated third-party rights.', 'verdict': 1}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question is specific and seeks information about the procedures for escalating incidents related to GAI systems to the organizational risk management authority, particularly when certain criteria for deactivation or disengagement are met. However, it assumes familiarity with the specific criteria and the context of GAI systems without providing any details. To improve clarity and answerability, the question could specify what the 'specific criteria' are or provide a brief context about GAI systems and their relevance to organizational risk management. This would help ensure that the question is understandable to a broader audience.\", 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] rewritten question: What procedures should be established and maintained for escalating GAI system incidents to the organizational risk management authority when specific criteria for deactivation or disengagement is met?\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question is specific and clear in its intent, asking about methods to maintain data privacy in GAI evaluations involving human subjects. It outlines the context (GAI evaluations) and the focus on compliance and individual privacy protection. However, it could be improved by specifying which applicable requirements are being referred to (e.g., GDPR, HIPAA) to provide a clearer framework for the answer. This would help in tailoring the response to specific legal or ethical standards.', 'verdict': 1}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about how data privacy is addressed in the technical companion to the Blueprint for an AI Bill of Rights. It is specific and has a clear intent, focusing on a particular document and aspect (data privacy). However, it assumes familiarity with the 'technical companion' and the 'Blueprint for an AI Bill of Rights' without providing any context or details about these documents. To improve clarity and answerability, the question could briefly describe what the Blueprint for an AI Bill of Rights entails or specify the aspects of data privacy being inquired about (e.g., principles, guidelines, specific measures).\", 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] retrying evolution: 1 times\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] multicontext question compressed: \"How to ensure data privacy in GAI evaluations with human subjects?\"\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 3, 'depth': 3, 'structure': 3, 'relevance': 3, 'score': 3.0}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['Automated systems', 'Protect the public from harm', 'Consultation', 'Testing', 'Risk identification and mitigation']\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the importance of considering human alternatives, consideration, and fallback in relation to the AI Bill of Rights. While it specifies a clear topic (AI Bill of Rights) and seeks to understand the significance of certain concepts (human alternatives, consideration, fallback), it lacks clarity regarding what is meant by 'consideration' and 'fallback'. These terms could be interpreted in various ways, leading to ambiguity in the response. To improve clarity and answerability, the question could define what is meant by 'human alternatives', 'consideration', and 'fallback' in this context, or specify the aspects of the AI Bill of Rights being referenced. This would help ensure that the intent is clear and that the question can be answered effectively.\", 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] retrying evolution: 1 times\n",
      "[ragas.testset.filters.DEBUG] evolution filter: {'reason': 'Both questions address the same topic of ensuring data privacy in evaluations involving human subjects in GAI applications, sharing the same constraints and requirements, as well as depth and breadth of inquiry.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.INFO] retrying evolution: 1 times\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"What are the key components of testing automated systems before deployment?\"\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 1, 'depth': 2, 'structure': 1, 'relevance': 2, 'score': 1.5}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['Racial equity', 'Supreme Court Decision', 'Automated society', 'Privacy protection', 'Crime prediction software']\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 3, 'structure': 2, 'relevance': 3, 'score': 2.5}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['Healthcare navigators', 'Automated customer service', 'Ballot curing laws', 'Fallback system', 'Voter signature matching algorithm']\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"What is the significance of the Executive Order On Advancing Racial Equity and Support for Underserved Communities Through the Federal Government?\"\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"How do ballot curing laws in at least 24 states require a fallback system for voters in case of issues with the voter signature matching algorithm?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question is specific and seeks information about the procedures for escalating incidents related to GAI systems to the organizational risk management authority, particularly when certain criteria for deactivation or disengagement are met. However, it assumes familiarity with terms like 'GAI system incidents' and 'organizational risk management authority' without providing definitions or context, which may hinder understanding for those not well-versed in the subject. To improve clarity and answerability, the question could define what constitutes a GAI system incident and outline the specific criteria for deactivation or disengagement. This would help ensure that the question is accessible to a broader audience.\", 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] retrying evolution: 1 times\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 3, 'structure': 2, 'relevance': 3, 'score': 2.5}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['GAI models', 'Synthetic NCII and CSAM', 'Value chain and component integration', 'Trustworthy AI characteristics', 'Suggested actions to manage GAI risks']\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks for the key components involved in testing automated systems prior to their deployment. It is specific and independent, as it does not rely on external references or additional context to be understood. The intent is clear, seeking a list or explanation of the components necessary for testing. Therefore, it meets the criteria for clarity and answerability.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"How do GAI value chains involve third-party components and what risks are associated with improper procurement or vetting of these components?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks about the significance of a specific Executive Order related to racial equity and support for underserved communities. It is clear in its intent, seeking to understand the importance or implications of the Executive Order. However, the question could be improved by providing a bit more context about the Executive Order itself, such as its main objectives or the specific aspects of significance being inquired about (e.g., social, economic, political implications). This would help ensure that the question is fully self-contained and answerable without requiring external references.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] simple question generated: \"What is the significance of the Executive Order On Advancing Racial Equity and Support for Underserved Communities Through the Federal Government?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about ballot curing laws in at least 24 states and their requirement for a fallback system related to voter signature matching algorithms. While it specifies the topic (ballot curing laws) and the context (voter signature matching), it is somewhat unclear due to the phrasing 'require a fallback system'. It could be interpreted in various ways, such as what specific fallback systems are in place or how they function. To improve clarity and answerability, the question could specify what aspects of the fallback system are of interest (e.g., types of systems, effectiveness, implementation) or provide a brief context about what ballot curing laws entail.\", 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] rewritten question: \"How do ballot curing laws in at least 24 states require a fallback system for voters in case of issues with the voter signature matching algorithm?\"\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] multicontext question generated: \"What are the key components of the Executive Order On Advancing Racial Equity and Support for Underserved Communities Through the Federal Government?\"\n",
      "[ragas.testset.evolutions.DEBUG] answer generated: {'answer': 'Systems should undergo extensive testing before deployment, following domain-specific best practices to ensure the technology will work in its real-world context. Testing should include both automated systems testing and human-led (manual) testing, with conditions mirroring those of the deployment environment. Performance should be compared with existing human-driven procedures, and decision possibilities should include the option of not deploying the system.', 'verdict': 1}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question is specific and clear in its intent, asking about the involvement of third-party components in GAI value chains and the associated risks of improper procurement or vetting. It does not rely on external references and can be understood independently. However, it could be improved by briefly defining 'GAI' for clarity, as not all readers may be familiar with the acronym. This would enhance the question's accessibility without compromising its specificity.\", 'verdict': 1}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks for the key components of a specific Executive Order related to racial equity and support for underserved communities. It is clear in its intent, specifying the document of interest (the Executive Order) and the type of information sought (key components). However, the question assumes familiarity with the Executive Order without providing any context or details about it, which may limit its answerability for those who are not aware of the document. To improve clarity and answerability, the question could include a brief description of the Executive Order or specify the aspects of the components that are of particular interest (e.g., policy areas, implementation strategies).', 'verdict': 1}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about ballot curing laws in at least 24 states and their requirement for a fallback system related to voter signature matching algorithms. While it specifies the topic (ballot curing laws) and the context (voter signature matching), it is somewhat unclear because it assumes knowledge of what 'ballot curing laws' entail and how they relate to fallback systems. Additionally, the phrase 'fallback system' could be interpreted in various ways without further clarification. To improve clarity and answerability, the question could define 'ballot curing laws' and explain what is meant by a 'fallback system', or specify the types of issues that might arise with the signature matching algorithm.\", 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] retrying evolution: 2 times\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] multicontext question compressed: \"What does the Executive Order on Advancing Racial Equity include?\"\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 2, 'structure': 2, 'relevance': 3, 'score': 2.25}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['OSTP conducted meetings', 'Private sector and civil society stakeholders', 'AI Bill of Rights', 'Positive use cases', 'Oversight possibilities']\n",
      "[ragas.testset.filters.DEBUG] evolution filter: {'reason': 'The first question asks about the significance of the Executive Order, while the second question inquires about its contents. This indicates a difference in depth and breadth of inquiry, as one seeks to understand importance and implications, while the other focuses on specific details.', 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"What organizations were involved in providing ideas related to oversight possibilities for AI technologies during the development of the Blueprint for an AI Bill of Rights?\"\n",
      "[ragas.testset.evolutions.DEBUG] answer generated: {'answer': 'GAI value chains involve many third-party components such as procured datasets, pre-trained models, and software libraries. Improper procurement or vetting of these components can lead to diminished transparency or accountability for downstream users. This is a risk for traditional AI systems and other digital technologies, but it is exacerbated for GAI due to the scale of the training data, the difficulty of training foundation models, and the extensive reuse of limited numbers of models. Additionally, errors in third-party GAI components can have downstream impacts on accuracy and robustness, such as inaccuracies in test datasets used for benchmarking or validation.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] answer generated: {'answer': 'The Executive Order on Advancing Racial Equity includes measures to support underserved communities through the federal government.', 'verdict': 1}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the organizations involved in providing ideas for oversight possibilities related to AI technologies during the development of the Blueprint for an AI Bill of Rights. It is specific in its intent and focuses on a particular topic, making it clear what information is being sought. However, the question assumes familiarity with the 'Blueprint for an AI Bill of Rights' without providing any context about it, which could hinder understanding for those who are not aware of this document. To improve clarity and answerability, the question could include a brief description of the Blueprint or specify the timeframe of its development, which would help contextualize the inquiry for a broader audience.\", 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] simple question generated: \"What organizations were involved in providing ideas related to oversight possibilities for AI technologies during the development of the Blueprint for an AI Bill of Rights?\"\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] multicontext question generated: \"Which organizations contributed ideas on oversight possibilities for AI technologies during the development of the Blueprint for an AI Bill of Rights?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks for specific organizations that contributed ideas regarding oversight possibilities for AI technologies in the context of the Blueprint for an AI Bill of Rights. It is clear in its intent and specifies the topic of interest, making it understandable. However, it assumes that the respondent has prior knowledge of the Blueprint for an AI Bill of Rights and the organizations involved, which may not be universally known. To improve clarity and answerability, the question could provide a brief context about the Blueprint for an AI Bill of Rights or specify the timeframe of interest, ensuring that the question is accessible to a broader audience.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] multicontext question compressed: \"Which organizations provided input on AI oversight for the AI Bill of Rights?\"\n",
      "[ragas.testset.filters.DEBUG] evolution filter: {'reason': 'Both questions inquire about organizations that contributed to the oversight of AI technologies in the context of the AI Bill of Rights. They share the same constraints and requirements, as well as similar depth and breadth of inquiry.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.INFO] retrying evolution: 2 times\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 3, 'structure': 2, 'relevance': 3, 'score': 2.5}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['Data privacy', 'Social media presence', 'Identity theft', 'Facial recognition system', 'Surveillance software']\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"Why is data privacy important and what problems does it seek to address and protect against?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks about the importance of data privacy and the problems it aims to address and protect against. It is clear in its intent, seeking information on both the significance of data privacy and the specific issues it mitigates. The question is independent and can be understood without needing additional context or references. However, it could be improved by specifying the context in which data privacy is being discussed (e.g., personal data, corporate data, legal frameworks) to provide a more focused response. Overall, the question is specific, independent, and has a clear intent.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] simple question generated: \"Why is data privacy important and what problems does it seek to address and protect against?\"\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] multicontext question generated: \"What foundational principle is crucial for achieving various objectives in the given framework, particularly in the context of surveillance, data collection, and privacy concerns?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about a foundational principle important for achieving objectives within a specific framework, particularly related to surveillance, data collection, and privacy concerns. While it identifies a clear area of interest (the foundational principle) and context (surveillance, data collection, privacy), it lacks specificity regarding what 'the given framework' refers to. This makes the question somewhat ambiguous, as it assumes the reader knows which framework is being discussed. To improve clarity and answerability, the question could specify the framework in question or provide a brief description of it. Additionally, clarifying what type of foundational principle is being sought (e.g., ethical, technical) would enhance the question's intent.\", 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] rewritten question: \"What foundational principle is crucial for achieving various objectives in the given framework, particularly in the context of surveillance, data collection, and privacy concerns?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about a foundational principle important for achieving objectives within a specific framework, particularly related to surveillance, data collection, and privacy concerns. While it identifies a clear area of interest (the foundational principle) and context (surveillance, data collection, privacy), it lacks specificity regarding what 'the given framework' refers to. This makes the question somewhat ambiguous, as it assumes the reader knows which framework is being discussed. To improve clarity and answerability, the question could specify the framework in question or provide a brief description of it. Additionally, clarifying what type of foundational principle is being sought (e.g., ethical, technical, legal) would enhance the question's clarity.\", 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] retrying evolution: 3 times\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 3, 'depth': 3, 'structure': 3, 'relevance': 3, 'score': 3.0}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['AI Bill of Rights', 'Automated systems', 'Civil rights and liberties', 'Equal opportunities', 'Access to critical resources']\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"How does the Blueprint for an AI Bill of Rights address civil rights, civil liberties, and privacy in relation to automated systems?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks how the Blueprint for an AI Bill of Rights addresses specific topics: civil rights, civil liberties, and privacy in relation to automated systems. It is clear in its intent and specifies the areas of interest, making it understandable. However, the question assumes familiarity with the 'Blueprint for an AI Bill of Rights' without providing any context or details about it. To improve clarity and answerability, the question could briefly describe what the Blueprint entails or specify the key aspects of civil rights, civil liberties, and privacy it is concerned with. This would help those unfamiliar with the document to better understand the question.\", 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] rewritten question: \"How does the Blueprint for an AI Bill of Rights address civil rights, civil liberties, and privacy in relation to automated systems?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks how the Blueprint for an AI Bill of Rights addresses specific topics: civil rights, civil liberties, and privacy in relation to automated systems. It is clear in its intent and specifies the areas of interest, making it understandable. However, the question assumes familiarity with the 'Blueprint for an AI Bill of Rights' without providing any context or details about it. To improve clarity and answerability, the question could briefly describe what the Blueprint entails or specify the key provisions or principles it includes regarding the mentioned topics.\", 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] retrying evolution: 4 times\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 3, 'structure': 2, 'relevance': 3, 'score': 2.5}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['TEVV metrics', 'Measurement error models', 'AI risks', 'Feedback processes', 'Impact assessments']\n",
      "[ragas.testset.evolutions.INFO] seed question generated: How can measurement error models be used to demonstrate construct validity for pre-deployment metrics in the MEASURE function?\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the application of measurement error models in demonstrating construct validity for pre-deployment metrics within the MEASURE function. It specifies the topic (measurement error models, construct validity, pre-deployment metrics, MEASURE function) and seeks a clear explanation of their relationship. However, the question may be challenging for those unfamiliar with the specific terminology or context of the MEASURE function and construct validity. To improve clarity and answerability, it would be beneficial to provide a brief definition or context for 'construct validity' and the 'MEASURE function', or to clarify what specific aspects of the measurement error models are of interest.\", 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] simple question generated: How can measurement error models be used to demonstrate construct validity for pre-deployment metrics in the MEASURE function?\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] multicontext question generated: \"How can the creation of measurement error models for pre-deployment metrics aid in demonstrating construct validity for the MEASURE function?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the role of measurement error models in demonstrating construct validity for the MEASURE function, which is a specific topic. However, it may not be clear to all readers what the 'MEASURE function' refers to, as it lacks context or definition. Additionally, the phrase 'pre-deployment metrics' could benefit from clarification regarding what specific metrics are being referred to. To improve clarity and answerability, the question could define the MEASURE function and provide examples of the pre-deployment metrics in question, making it more accessible to a broader audience.\", 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] rewritten question: \"How can the creation of measurement error models for pre-deployment metrics aid in demonstrating construct validity for the MEASURE function?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the role of measurement error models in demonstrating construct validity for the MEASURE function, which is a specific topic. However, it may not be clear to all readers what the 'MEASURE function' refers to, as it lacks context or definition. Additionally, the phrase 'pre-deployment metrics' could benefit from further clarification regarding what specific metrics are being referred to. To improve clarity and answerability, the question could define the MEASURE function and provide examples of the pre-deployment metrics in question, making it more accessible to a broader audience.\", 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] retrying evolution: 4 times\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 3, 'structure': 2, 'relevance': 3, 'score': 2.5}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['Regular engagement with AI Actors', 'Feedback integration', 'Unanticipated impacts', 'Measurement of AI risks', 'Content provenance']\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"How are AI risks measured and evaluated in the context of GAI systems?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks about the measurement and evaluation of AI risks specifically in the context of General Artificial Intelligence (GAI) systems. It is clear in its intent, specifying the focus on AI risks and GAI systems, which allows for a relevant response. The question is also independent, as it does not rely on external references or additional context to be understood. Therefore, it meets the criteria for clarity and answerability.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] simple question generated: \"How are AI risks measured and evaluated in the context of GAI systems?\"\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] multicontext question generated: \"How can AI risks be effectively measured and evaluated in the context of GAI systems, considering both the identification of new impacts and the explanation and documentation of AI models?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question addresses the measurement and evaluation of AI risks specifically in the context of General Artificial Intelligence (GAI) systems. It clearly specifies the focus on both identifying new impacts and the explanation and documentation of AI models, which indicates a clear intent. However, the question is somewhat complex and may benefit from simplification or breaking down into more specific sub-questions to enhance clarity. For example, it could separately ask about methods for identifying new impacts and then inquire about best practices for explaining and documenting AI models. This would make it easier to address each aspect without overwhelming the respondent.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] multicontext question compressed: \"How to measure AI risks in GAI systems, including new impacts and model documentation?\"\n",
      "[ragas.testset.filters.DEBUG] evolution filter: {'reason': \"Both questions focus on measuring and evaluating AI risks specifically in the context of GAI systems. However, the second question introduces additional elements such as 'new impacts' and 'model documentation', which expands the breadth of inquiry beyond the first question.\", 'verdict': 0}\n",
      "[ragas.testset.evolutions.DEBUG] answer generated: {'answer': 'The answer to given question is not present in context', 'verdict': -1}\n"
     ]
    }
   ],
   "source": [
    "testset = generator.generate_with_langchain_docs(documents, 5, distributions, with_debugging_logs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>contexts</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>evolution_type</th>\n",
       "      <th>metadata</th>\n",
       "      <th>episode_done</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How do GAI value chains involve third-party co...</td>\n",
       "      <td>[ \\n12 \\nCSAM. Even when trained on “clean” da...</td>\n",
       "      <td>GAI value chains involve many third-party comp...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'https://nvlpubs.nist.gov/nistpubs...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How can organizations verify information shari...</td>\n",
       "      <td>[ \\n20 \\nGV-4.3-003 \\nVerify information shari...</td>\n",
       "      <td>Organizations can verify information sharing a...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'https://nvlpubs.nist.gov/nistpubs...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How to measure AI risks in GAI systems, includ...</td>\n",
       "      <td>[ \\n28 \\nMAP 5.2: Practices and personnel for ...</td>\n",
       "      <td>The answer to given question is not present in...</td>\n",
       "      <td>multi_context</td>\n",
       "      <td>[{'source': 'https://nvlpubs.nist.gov/nistpubs...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What does the Executive Order on Advancing Rac...</td>\n",
       "      <td>[ \\n \\n \\n \\nENDNOTES\\n1.The Executive Order O...</td>\n",
       "      <td>The Executive Order on Advancing Racial Equity...</td>\n",
       "      <td>multi_context</td>\n",
       "      <td>[{'source': 'https://www.whitehouse.gov/wp-con...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What are the key components of testing automat...</td>\n",
       "      <td>[ \\n \\n \\n \\n \\n \\n \\nSAFE AND EFFECTIVE \\nSYS...</td>\n",
       "      <td>Systems should undergo extensive testing befor...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'https://www.whitehouse.gov/wp-con...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  How do GAI value chains involve third-party co...   \n",
       "1  How can organizations verify information shari...   \n",
       "2  How to measure AI risks in GAI systems, includ...   \n",
       "3  What does the Executive Order on Advancing Rac...   \n",
       "4  What are the key components of testing automat...   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  [ \\n12 \\nCSAM. Even when trained on “clean” da...   \n",
       "1  [ \\n20 \\nGV-4.3-003 \\nVerify information shari...   \n",
       "2  [ \\n28 \\nMAP 5.2: Practices and personnel for ...   \n",
       "3  [ \\n \\n \\n \\nENDNOTES\\n1.The Executive Order O...   \n",
       "4  [ \\n \\n \\n \\n \\n \\n \\nSAFE AND EFFECTIVE \\nSYS...   \n",
       "\n",
       "                                        ground_truth evolution_type  \\\n",
       "0  GAI value chains involve many third-party comp...         simple   \n",
       "1  Organizations can verify information sharing a...         simple   \n",
       "2  The answer to given question is not present in...  multi_context   \n",
       "3  The Executive Order on Advancing Racial Equity...  multi_context   \n",
       "4  Systems should undergo extensive testing befor...         simple   \n",
       "\n",
       "                                            metadata  episode_done  \n",
       "0  [{'source': 'https://nvlpubs.nist.gov/nistpubs...          True  \n",
       "1  [{'source': 'https://nvlpubs.nist.gov/nistpubs...          True  \n",
       "2  [{'source': 'https://nvlpubs.nist.gov/nistpubs...          True  \n",
       "3  [{'source': 'https://www.whitehouse.gov/wp-con...          True  \n",
       "4  [{'source': 'https://www.whitehouse.gov/wp-con...          True  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset.to_pandas()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
